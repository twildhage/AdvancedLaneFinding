import numpy as np
import cv2

def random_affine_transformation(image, angle, shear_range=200):
    """
    The following code is adapted from:
    https://medium.com/@ksakmann/behavioral-cloning-make-a-car-drive-like-yourself-dc6021152713#.7k8vfppvk
    The function performs an affine transformation on the original image. This results in a
    new image, which still has a valid perspective but with a significantly altered
    steering angle. This allows to generate any real valued steering angle within
    the valid range defined by the shearing range. The main result is a smooth
    distributed dataset w.r.t. the steering angle.

    :image:
        source image on which the shear operation will be applied
    :angle:
        steering angle of the image
    :shear_range:
        random shear between [-shear_range, shear_range] will be applied
    :return:
        The image generated by applying random shear on the source image
    """
    rows, cols = image.shape[0:2]
    dx = np.random.randint(-shear_range, shear_range)
    random_point = [cols/2 + dx, rows/2]
    triangle1 = np.float32([[0,         rows],
                            [cols,      rows],
                            [cols/2,    rows/2]])
    triangle2 = np.float32([[0,    rows],
                            [cols, rows],
                            random_point])

    steering_correction = dx / (rows / 2) * 360 / (2 * np.pi * 25.0) / 6.0
    transf_matrix = cv2.getAffineTransform(triangle1, triangle2)
    #print(triangle2[2,0]-triangle1[2,0])
    #print(transf_matrix)
    image = cv2.warpAffine(image, transf_matrix, (cols, rows), borderMode=1)
    angle += steering_correction

    return image, angle


def lane_detection(img, kernel_size=3, thresholds_dict={'gradient':(30,100), 'magnitude':(70,100), 'direction':(0.8, 0.9),
                       's_channel':(100,255), 'r_channel':(150,255), 'u_channel':(140,180)}, verbose=1):

    def binary_threshold(scaled_image, thresholds=(20, 140)):
        binary_image = np.zeros_like(scaled_image)
        binary_image[(scaled_image > thresholds[0]) & (scaled_image <= thresholds[1])] = 1
        return binary_image
    
    def scale(image, max_value=255):
        normalized = np.absolute(image)/np.max(np.absolute(image))
        return (max_value * normalized).astype(type(max_value))
    
    # Convert to grayscale
    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
    
    # HLS colour
    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)
    S = hls[:,:,2]
    binary_s = binary_threshold(scale(S), thresholds['s_channel'])
    
    # RGB colour
    R = img[:,:,0]
    binary_r = binary_threshold(scale(R), thresholds['r_channel'])

    channel = gray
    
    # Apply Sobel algorithm the get x,y gradients 
    gradx = cv2.Sobel(channel, cv2.CV_64F, 1, 0, ksize=kernel_size)
    grady = cv2.Sobel(channel, cv2.CV_64F, 0, 1, ksize=kernel_size)
    
    # Binary gradient in x-direction
    binary_gradx = binary_threshold(scale(gradx), thresholds_dict['gradient'])
    
    # Binary gradient in x-direction
    binary_grady = binary_threshold(scale(grady), thresholds_dict['gradient'])
    
    # Gradient x,y magnitude
    mag_gradxy = np.sqrt(gradx**2 + grady**2)
    binary_mag_gradxy = binary_threshold(scale(mag_gradxy), thresholds_dict['magnitude'])
    
    # Get binary direction
    dir_gradxy = np.arctan2(np.absolute(grady), np.absolute(gradx))
    binary_dir = binary_threshold(scale(dir_gradxy, 1.0), thresholds_dict['direction'])
    
    binary_combined = np.zeros_like(binary_dir)
    binary_combined[((binary_gradx == 1)      & (binary_grady == 1)) |
             ((binary_mag_gradxy == 1) & (binary_dir == 1)) |
                   ((binary_r == 1) &  (binary_s ==1))] = 1
    
    if verbose==1:
        fig, axes = plt.subplots(3,2, figsize=(20,10))
        axes[0,0].imshow(scale(mag_gradxy), cmap='hot')
        axes[0,0].set_title("magnitude")
        axes[0,1].imshow(scale(dir_gradxy, 1.0), cmap='hot')
        axes[0,1].set_title("direction")
        axes[1,0].imshow(scale(gradx), cmap='hot')
        axes[1,0].set_title("gradient x")
        axes[1,1].imshow(scale(grady), cmap='hot')
        axes[1,1].set_title("gradient y")
        axes[2,0].imshow(scale(R), cmap='hot')
        axes[2,0].set_title("R channel")
        axes[2,1].imshow(scale(S), cmap='hot')
        axes[2,1].set_title("S channel")
        plt.show()
    
        fig, axes = plt.subplots(3,2, figsize=(20,10))
        axes[0,0].imshow(binary_mag_gradxy, cmap='gray')
        axes[0,0].set_title("magnitude")
        axes[0,1].imshow(binary_dir, cmap='gray')
        axes[0,1].set_title("direction")
        axes[1,0].imshow(binary_gradx, cmap='gray')
        axes[1,0].set_title("gradient x")
        axes[1,1].imshow(binary_grady, cmap='gray')
        axes[1,1].set_title("gradient y")
        axes[2,0].imshow(binary_r, cmap='gray')
        axes[2,0].set_title("binary r")
        axes[2,1].imshow(binary_s, cmap='gray')
        axes[2,1].set_title("binary s")
        plt.show()
    
        
    return binary_combined

def get_calibration_parameters(images, verbose=1):
    
    # Use cv2.calibrateCamera() and cv2.undistort()
    imgpoints = [] # 2D
    objpoints = [] # 3D
    nx = 9
    ny = 6
    objp = np.zeros((nx*ny, 3), np.float32)
    objp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1,2)

    distortion_coefficients = []
    camera_matrices = []
    singuar_values = []
    
    for number, img in enumerate(images):
        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)

        # Finding chessboard corners (for an 9x6 board):
        ret, corners = cv2.findChessboardCorners(gray, (nx,ny), None)
        if verbose==1:
            print("Image: {0}\t found corners: {1}".format(number, ret))

        if ret==True:
            imgpoints.append(corners)
            objpoints.append(objp)

            # Drawing detected corners on an image:
            img = cv2.drawChessboardCorners(img, (nx,ny), corners, ret)

            # Camera calibration, given object points, image points, and the shape of the grayscale image:
            ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)

            camera_matrices.append(mtx)
            distortion_coefficients.append(dist)
    
    for cm in camera_matrices:
        U, s, V = np.linalg.svd(cm, full_matrices=True)
        singuar_values.append(s)
        
    distortion_coefficients = np.array(distortion_coefficients).squeeze()
    camera_matrices = np.array(camera_matrices).squeeze()
    singuar_values = np.array(singuar_values)
    
    return camera_matrices, distortion_coefficients, singuar_values
        
def lane_func(par, x):
    """
    This function returns the error according to a quadratic model 
    """
    return (par[0] * x**2 + par[1] * x + par[2]) 

def error_func(par, func, x, y):
    return func(par, x) - y

def robust_lane_fit(x, y, verbose=0):
    """
    This function performs a robust least square fit according to a 
    linear model. The term 'robust' refers to the insensitivity to outliners.
    The names 'll', 'rl' rever to left and right lines.
    """
    
    # initialize parameters par: (slope, bias)
    par0 = np.array([-0.5, 1, 1])
    # Set f_scale to 0.1 which means that inlier residuals are approximately lower than 0.1.
    f_scale = 0.1
    
    # Run robust least squares with loss='soft_l1', 
    res_robust = least_squares(error_func, par0, args=(lane_func, x, y), 
                               loss='soft_l1', f_scale=f_scale, verbose=verbose)
    # Get parameters 
    #a, b, c = res_robust.x
    # Calculate average line at given x coordinates
    #x_fit = np.array([0, x_range])
    #y_fit = a * x_fit**2 + b * x_fit + c
    # Reorganize x,y coordinates of points as line
    lane = []
    return res_robust
